{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import merged_dataframes\n",
    "from confluent_kafka import Producer\n",
    "import json\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bootstrap_server = 'pkc-9q8rv.ap-south-2.aws.confluent.cloud:9092'\n",
    "API_key = 'XOZNRBMGQYEJNLMX'\n",
    "API_secret = '99ETgxUsjRP/XYXrMJ9jE3GxOqrsYErw4hRfE3i/VZzcylc6xPivFODrwfi5ovUQ'\n",
    "SECURITY_PROTOCOL = 'SASL_SSL'\n",
    "SSL_MACHENISM = 'PLAIN'\n",
    "\n",
    "producer_config = {\n",
    "    'sasl.mechanism': SSL_MACHENISM,\n",
    "    'bootstrap.servers':Bootstrap_server,\n",
    "    'security.protocol': SECURITY_PROTOCOL,\n",
    "    'sasl.username': API_key,\n",
    "    'sasl.password': API_secret\n",
    "    'enable.idempotence': True   #to ensure indempotence means to neglet duplicate data\n",
    "}\n",
    "\n",
    "producer = Producer(producer_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [ 'Top_10_open','Top_10_close','Top_10_volume' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_records(df,topic:str):\n",
    "    for _, row in df.iterrows():\n",
    "        # Convert the key and value to JSON format\n",
    "        # key = json.dumps(row['key'])\n",
    "        # value = json.dumps(row['value'])\n",
    "        the_message = row.to_dict()    \n",
    "        message = json.dumps(the_message)\n",
    "        # Send record to Kafka topic\n",
    "        producer.produce(topic,value=message)\n",
    "\n",
    "    # Flush the producer to ensure all messages are sent\n",
    "    producer.flush()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_offset = -1\n",
    "try:\n",
    "    with open ('checkpoints.txt','r') as f:\n",
    "        last_offset = int(f.readline())\n",
    "except FileNotFoundError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_records = df[df.index > last_offset]\n",
    "\n",
    "if not new_records.empty:\n",
    "    produce_records(new_records)\n",
    "    \n",
    "    last_offset = df.index.max()\n",
    "    \n",
    "    with open ('checkpoints.txt','r') as f:\n",
    "        f.write(str(last_offset))\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
